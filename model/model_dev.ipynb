{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Text Classification Development\n",
    "\n",
    "Purpose:\n",
    "This model predicts a Company's business category based on the text of their homepage website. \n",
    "\n",
    "Hypothesis: \n",
    "The implicit hypothesis is that websites within each category will use distinctive language that can be used to classify them.\n",
    "\n",
    "Overall process:\n",
    "1. Normalize Text (done during eda.ipynb to complete EDA)\n",
    "2. Label Encoding\n",
    "3. Feature Extraction (TFIDF & BERT)\n",
    "4. Model Training\n",
    "5. Evaulate best performing model and vectorization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data back in from pickle file created with eda.ipynb\n",
    "\n",
    "# Dynamically get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "text_path = os.path.abspath(os.path.join(current_dir, '..', 'output','combined_data.pkl'))\n",
    "\n",
    "# read data back in \n",
    "df_clean = pd.read_pickle(text_path)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corporate Services' 'Media, Marketing & Sales' 'Healthcare'\n",
      " 'Industrials' 'Commercial Services & Supplies' 'Consumer Discretionary'\n",
      " 'Transportation & Logistics' 'Energy & Utilities' 'Financials'\n",
      " 'Professional Services' 'Consumer Staples' 'Materials'\n",
      " 'Information Technology']\n",
      "[ 3 10  6  7  0  1 12  4  5 11  2  9  8]\n"
     ]
    }
   ],
   "source": [
    "#Turning the labels into numbers\n",
    "label_encoder = LabelEncoder()\n",
    "df_clean['Category_encoded'] = label_encoder.fit_transform(df_clean['Category'])\n",
    "print(df_clean['Category'].unique())\n",
    "print(df_clean['Category_encoded'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "I'm going to use k-fold cross-validation to evaluate my models later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71415,)\n",
      "(71415,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into features (X) and labels (y)\n",
    "X = df_clean['clean_text_str']\n",
    "y = df_clean['Category_encoded']\n",
    "\n",
    "print (X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42) # using the normal 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classification models to be tested\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(multi_class='ovr', max_iter=1000),\n",
    "    'Support Vector Classifier': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "I've chosen the following models to test: \n",
    "1. Naive Bayes\n",
    "    - This model is extremely fast and in production can be used as an 'online' model (i.e. can be updated in real time)\n",
    "    - MultinomialNB is usually very good with discrete features like word counts \n",
    "    - Can always improve this by adding nontext features\n",
    "2. Logistic Regression\n",
    "3. Support Vector Classifier\n",
    "4. Decision Tree\n",
    "5. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorization with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. TF-IDF Pipeline\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),  # TF-IDF Vectorization\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\megan\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\megan\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\megan\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### 2. BERT Embeddings Pipeline (Custom Transformer)\n",
    "class BERTEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='bert-base-uncased', max_length=128):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        embeddings = []\n",
    "        for sentence in X:\n",
    "            tokens = self.tokenizer(sentence, padding='max_length', truncation=True, return_tensors='pt', max_length=self.max_length)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**tokens)\n",
    "            embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "        return embeddings\n",
    "\n",
    "bert_pipeline = Pipeline([\n",
    "    ('bert', BERTEmbeddingTransformer()),  # BERT Embeddings\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results for comparison\n",
    "results = []\n",
    "\n",
    "# Iterate over the models and compare pipelines (TF-IDF vs BERT embeddings)\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    ### TF-IDF Pipeline\n",
    "    tfidf_model_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),\n",
    "        (model_name, model)\n",
    "    ])\n",
    "\n",
    "    # Cross-Validation for TF-IDF\n",
    "    tfidf_scores = cross_val_score(tfidf_model_pipeline, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    \n",
    "    # Train on TF-IDF\n",
    "    tfidf_model_pipeline.fit(X_train, y_train)\n",
    "    y_pred_tfidf = tfidf_model_pipeline.predict(X_test)\n",
    "    tfidf_accuracy = accuracy_score(y_test, y_pred_tfidf)\n",
    "    tfidf_report = classification_report(y_test, y_pred_tfidf, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "    # Store TF-IDF results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Pipeline': 'TF-IDF',\n",
    "        'Cross_Val_Accuracy': tfidf_scores.mean(),\n",
    "        'Test_Accuracy': tfidf_accuracy,\n",
    "        'Precision': tfidf_report['weighted avg']['precision'],\n",
    "        'Recall': tfidf_report['weighted avg']['recall'],\n",
    "        'F1-Score': tfidf_report['weighted avg']['f1-score']\n",
    "    })\n",
    "    \n",
    "    ### BERT Pipeline\n",
    "    bert_model_pipeline = Pipeline([\n",
    "        ('bert', BERTEmbeddingTransformer()),  # BERT Embeddings\n",
    "        (model_name, model)\n",
    "    ])\n",
    "\n",
    "    # Cross-Validation for BERT\n",
    "    bert_scores = cross_val_score(bert_model_pipeline, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    \n",
    "    # Train on BERT\n",
    "    bert_model_pipeline.fit(X_train, y_train)\n",
    "    y_pred_bert = bert_model_pipeline.predict(X_test)\n",
    "    bert_accuracy = accuracy_score(y_test, y_pred_bert)\n",
    "    bert_report = classification_report(y_test, y_pred_bert, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "    # Store BERT results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Pipeline': 'BERT',\n",
    "        'Cross_Val_Accuracy': bert_scores.mean(),\n",
    "        'Test_Accuracy': bert_accuracy,\n",
    "        'Precision': bert_report['weighted avg']['precision'],\n",
    "        'Recall': bert_report['weighted avg']['recall'],\n",
    "        'F1-Score': bert_report['weighted avg']['f1-score']\n",
    "    })\n",
    "\n",
    "# Create DataFrame for all the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results for comparison\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-91906e0791fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# initialize list to store results for comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Iterate over the models and compare pipelines (TF-IDF vs BERT embeddings)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n=== {model_name} ===\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize list to store results for comparison\n",
    "results = []\n",
    "# Iterate over the models and compare pipelines (TF-IDF vs BERT embeddings)\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    \n",
    "    ### TF-IDF Pipeline\n",
    "    tfidf_model_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),\n",
    "        (model_name, model)\n",
    "    ])\n",
    "\n",
    "    # Cross-Validation for TF-IDF\n",
    "    tfidf_scores = cross_val_score(tfidf_model_pipeline, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    print(f\"TF-IDF {model_name} Cross-Validation Accuracy: {tfidf_scores.mean():.4f}\")\n",
    "    \n",
    "    # Train on TF-IDF\n",
    "    tfidf_model_pipeline.fit(X_train, y_train)\n",
    "    y_pred_tfidf = tfidf_model_pipeline.predict(X_test)\n",
    "    print(f\"TF-IDF {model_name} Confusion Matrix of Category Performance:\")\n",
    "    print(classification_report(y_test, y_pred_tfidf, target_names=label_encoder.classes_))\n",
    "\n",
    "    ### BERT Pipeline\n",
    "    bert_model_pipeline = Pipeline([\n",
    "        ('bert', BERTEmbeddingTransformer()),  # BERT Embeddings\n",
    "        (model_name, model)\n",
    "    ])\n",
    "\n",
    "      # Cross-Validation for BERT\n",
    "    bert_scores = cross_val_score(bert_model_pipeline, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "    print(f\"BERT {model_name} Cross-Validation Accuracy: {bert_scores.mean():.4f}\")\n",
    "    \n",
    "    # Train on BERT\n",
    "    bert_model_pipeline.fit(X_train, y_train)\n",
    "    y_pred_bert = bert_model_pipeline.predict(X_test)\n",
    "    print(f\"BERT {model_name} Confusion Matrix of Category Performance:\")\n",
    "    print(classification_report(y_test, y_pred_bert, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
